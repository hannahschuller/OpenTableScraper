{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8abbf7fe-e471-4be7-a558-da24b58a5438",
   "metadata": {},
   "source": [
    "**OpenTable reservation time scraper**\n",
    "\n",
    "Link: https://www.opentable.co.uk/s?dateTime=2026-01-31T23%3A30%3A00&covers=2&metroId=3146&shouldUseLatLongSearch=false&originCorrelationId=6b9e96ee-1ae5-4791-a91a-e60d7091faf0&corrid=77e4b75f-cde3-4d45-b7b1-14790e7f372f&queryUnderstandingType=none&showMap=true&sortBy=web_conversion\n",
    "\n",
    "31st Jan 2026, 23:30, 2px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "103642e4-7a1d-4264-b51d-c446be9cc3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "!pip install selenium webdriver-manager beautifulsoup4\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810f4b24-b22c-4f99-8068-8af372e91eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aberdeen\n",
    "import csv\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import undetected_chromedriver as uc\n",
    "\n",
    "URL = \"https://www.opentable.co.uk/s?dateTime=2026-01-31T23%3A30%3A00&covers=2&metroId=3029&regionIds%5B%5D=&neighborhoodIds%5B%5D=&term=&shouldUseLatLongSearch=false\"\n",
    "\n",
    "def scrape_opentable_uc_scroll(url):\n",
    "    print(\"[1/6] Creating fresh Chrome options...\")\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.headless = False  # make browser visible\n",
    "\n",
    "    print(\"[2/6] Launching undetected Chrome...\")\n",
    "    driver = uc.Chrome(options=options, version_main=142)\n",
    "\n",
    "    try:\n",
    "        print(\"[3/6] Loading OpenTable page...\")\n",
    "        driver.get(url)\n",
    "        time.sleep(3)\n",
    "\n",
    "        # ----- SCROLL SLOWLY TO LOAD ALL CARDS -----\n",
    "        print(\"[4/6] Scrolling page to load all restaurants...\")\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        while True:\n",
    "            driver.execute_script(\"window.scrollBy(0, 500);\")  # scroll down 500px\n",
    "            time.sleep(1)  # wait for lazy-loaded content\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break  # reached bottom\n",
    "            last_height = new_height\n",
    "\n",
    "        print(\"[5/6] Extracting restaurant data...\")\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        cards = soup.find_all(\"div\", attrs={\"data-test\": \"restaurant-card\"})\n",
    "        print(f\"Found {len(cards)} restaurant cards.\\n\")\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for idx, card in enumerate(cards, start=1):\n",
    "            print(f\" → Processing restaurant {idx}/{len(cards)}\")\n",
    "            try:\n",
    "                restaurant_id = card.get(\"data-rid\")\n",
    "\n",
    "                name_tag = card.find(\"a\", attrs={\"data-test\": \"res-card-name\"})\n",
    "                name = name_tag.get_text(strip=True) if name_tag else None\n",
    "\n",
    "                rating_tag = card.select_one(\".tSiVMQB9es0-\")\n",
    "                rating = rating_tag.get_text(strip=True) if rating_tag else None\n",
    "\n",
    "                review_tag = card.find(\"a\", attrs={\"href\": lambda x: x and \"#reviews\" in x})\n",
    "                reviews = review_tag.get_text(strip=True) if review_tag else None\n",
    "\n",
    "                price_tag = card.select_one(\".Vk-xtpOrXcE-\")\n",
    "                price = price_tag.get_text(strip=True) if price_tag else None\n",
    "\n",
    "                cuisine_tag = card.select_one('[data-test=\"cuisine-and-location\"]')\n",
    "                cuisine_location = cuisine_tag.get_text(strip=True) if cuisine_tag else None\n",
    "\n",
    "                slots = [\n",
    "                    slot.get_text(strip=True)\n",
    "                    for slot in card.select('[data-test^=\"time-slot\"] div')\n",
    "                    if slot.get_text(strip=True)\n",
    "                ]\n",
    "\n",
    "                results.append({\n",
    "                    \"restaurant_id\": restaurant_id,\n",
    "                    \"name\": name,\n",
    "                    \"rating\": rating,\n",
    "                    \"reviews\": reviews,\n",
    "                    \"price\": price,\n",
    "                    \"cuisine_location\": cuisine_location,\n",
    "                    \"timeslots\": \", \".join(slots),\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   ! Error processing card {idx}: {e}\")\n",
    "\n",
    "            time.sleep(0.05)\n",
    "\n",
    "        print(\"\\n[6/6] Saving results to CSV...\")\n",
    "        with open(\"restaurants.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=[\n",
    "                \"restaurant_id\", \"name\", \"rating\", \"reviews\",\n",
    "                \"price\", \"cuisine_location\", \"timeslots\"\n",
    "            ])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(results)\n",
    "\n",
    "        print(\"Scraping complete! Saved as restaurants.csv\\n\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_opentable_uc_scroll(URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae06692e-da5d-4e78-bc20-049b3d7006cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/6] Creating fresh Chrome options...\n",
      "[2/6] Launching undetected Chrome...\n",
      "\n",
      "[3/6] Processing page 1...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 50 restaurant cards on page 1.\n",
      " → Processing restaurant 1/50\n",
      " → Processing restaurant 2/50\n",
      " → Processing restaurant 3/50\n",
      " → Processing restaurant 4/50\n",
      " → Processing restaurant 5/50\n",
      " → Processing restaurant 6/50\n",
      " → Processing restaurant 7/50\n",
      " → Processing restaurant 8/50\n",
      " → Processing restaurant 9/50\n",
      " → Processing restaurant 10/50\n",
      " → Processing restaurant 11/50\n",
      " → Processing restaurant 12/50\n",
      " → Processing restaurant 13/50\n",
      " → Processing restaurant 14/50\n",
      " → Processing restaurant 15/50\n",
      " → Processing restaurant 16/50\n",
      " → Processing restaurant 17/50\n",
      " → Processing restaurant 18/50\n",
      " → Processing restaurant 19/50\n",
      " → Processing restaurant 20/50\n",
      " → Processing restaurant 21/50\n",
      " → Processing restaurant 22/50\n",
      " → Processing restaurant 23/50\n",
      " → Processing restaurant 24/50\n",
      " → Processing restaurant 25/50\n",
      " → Processing restaurant 26/50\n",
      " → Processing restaurant 27/50\n",
      " → Processing restaurant 28/50\n",
      " → Processing restaurant 29/50\n",
      " → Processing restaurant 30/50\n",
      " → Processing restaurant 31/50\n",
      " → Processing restaurant 32/50\n",
      " → Processing restaurant 33/50\n",
      " → Processing restaurant 34/50\n",
      " → Processing restaurant 35/50\n",
      " → Processing restaurant 36/50\n",
      " → Processing restaurant 37/50\n",
      " → Processing restaurant 38/50\n",
      " → Processing restaurant 39/50\n",
      " → Processing restaurant 40/50\n",
      " → Processing restaurant 41/50\n",
      " → Processing restaurant 42/50\n",
      " → Processing restaurant 43/50\n",
      " → Processing restaurant 44/50\n",
      " → Processing restaurant 45/50\n",
      " → Processing restaurant 46/50\n",
      " → Processing restaurant 47/50\n",
      " → Processing restaurant 48/50\n",
      " → Processing restaurant 49/50\n",
      " → Processing restaurant 50/50\n",
      "\n",
      "[3/6] Processing page 2...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 45 restaurant cards on page 2.\n",
      " → Processing restaurant 1/45\n",
      " → Processing restaurant 2/45\n",
      " → Processing restaurant 3/45\n",
      " → Processing restaurant 4/45\n",
      " → Processing restaurant 5/45\n",
      " → Processing restaurant 6/45\n",
      " → Processing restaurant 7/45\n",
      " → Processing restaurant 8/45\n",
      " → Processing restaurant 9/45\n",
      " → Processing restaurant 10/45\n",
      " → Processing restaurant 11/45\n",
      " → Processing restaurant 12/45\n",
      " → Processing restaurant 13/45\n",
      " → Processing restaurant 14/45\n",
      " → Processing restaurant 15/45\n",
      " → Processing restaurant 16/45\n",
      " → Processing restaurant 17/45\n",
      " → Processing restaurant 18/45\n",
      " → Processing restaurant 19/45\n",
      " → Processing restaurant 20/45\n",
      " → Processing restaurant 21/45\n",
      " → Processing restaurant 22/45\n",
      " → Processing restaurant 23/45\n",
      " → Processing restaurant 24/45\n",
      " → Processing restaurant 25/45\n",
      " → Processing restaurant 26/45\n",
      " → Processing restaurant 27/45\n",
      " → Processing restaurant 28/45\n",
      " → Processing restaurant 29/45\n",
      " → Processing restaurant 30/45\n",
      " → Processing restaurant 31/45\n",
      " → Processing restaurant 32/45\n",
      " → Processing restaurant 33/45\n",
      " → Processing restaurant 34/45\n",
      " → Processing restaurant 35/45\n",
      " → Processing restaurant 36/45\n",
      " → Processing restaurant 37/45\n",
      " → Processing restaurant 38/45\n",
      " → Processing restaurant 39/45\n",
      " → Processing restaurant 40/45\n",
      " → Processing restaurant 41/45\n",
      " → Processing restaurant 42/45\n",
      " → Processing restaurant 43/45\n",
      " → Processing restaurant 44/45\n",
      " → Processing restaurant 45/45\n",
      "\n",
      "[5/6] Saving results to 'birmingham_west_midlands.csv'...\n",
      "[6/6] Scraping complete! Total restaurants: 95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# birmingham\n",
    "URL = \"https://www.opentable.co.uk/s?dateTime=2026-01-31T23%3A30%3A00&covers=2&metroId=3146&shouldUseLatLongSearch=false&originCorrelationId=6b9e96ee-1ae5-4791-a91a-e60d7091faf0&corrid=77e4b75f-cde3-4d45-b7b1-14790e7f372f&queryUnderstandingType=none&showMap=true&sortBy=web_conversion\"\n",
    "\n",
    "def scrape_opentable_birmingham_one_click(url):\n",
    "    print(\"[1/6] Creating fresh Chrome options...\")\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.headless = False  # make browser visible\n",
    "\n",
    "    print(\"[2/6] Launching undetected Chrome...\")\n",
    "    driver = uc.Chrome(options=options, version_main=142)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        page_number = 1\n",
    "        next_clicked = False  # flag to click next page only once\n",
    "\n",
    "        while True:\n",
    "            print(f\"\\n[3/6] Processing page {page_number}...\")\n",
    "            time.sleep(3)\n",
    "\n",
    "            # ----- SCROLL SLOWLY TO LOAD ALL CARDS -----\n",
    "            print(\"[4/6] Scrolling page to load all restaurants...\")\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            while True:\n",
    "                driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "                time.sleep(1)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "\n",
    "            # Parse page\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            cards = soup.find_all(\"div\", attrs={\"data-test\": \"restaurant-card\"})\n",
    "            print(f\"Found {len(cards)} restaurant cards on page {page_number}.\")\n",
    "\n",
    "            # Extract info\n",
    "            for idx, card in enumerate(cards, start=1):\n",
    "                print(f\" → Processing restaurant {idx}/{len(cards)}\")\n",
    "                try:\n",
    "                    restaurant_id = card.get(\"data-rid\")\n",
    "\n",
    "                    name_tag = card.find(\"a\", attrs={\"data-test\": \"res-card-name\"})\n",
    "                    name = name_tag.get_text(strip=True) if name_tag else None\n",
    "\n",
    "                    rating_tag = card.select_one(\".tSiVMQB9es0-\")\n",
    "                    rating = rating_tag.get_text(strip=True) if rating_tag else None\n",
    "\n",
    "                    review_tag = card.find(\"a\", attrs={\"href\": lambda x: x and \"#reviews\" in x})\n",
    "                    reviews = review_tag.get_text(strip=True) if review_tag else None\n",
    "\n",
    "                    price_tag = card.select_one(\".Vk-xtpOrXcE-\")\n",
    "                    price = price_tag.get_text(strip=True) if price_tag else None\n",
    "\n",
    "                    cuisine_tag = card.select_one('[data-test=\"cuisine-and-location\"]')\n",
    "                    cuisine_location = cuisine_tag.get_text(strip=True) if cuisine_tag else None\n",
    "\n",
    "                    slots = [\n",
    "                        slot.get_text(strip=True)\n",
    "                        for slot in card.select('[data-test^=\"time-slot\"] div')\n",
    "                        if slot.get_text(strip=True)\n",
    "                    ]\n",
    "\n",
    "                    all_results.append({\n",
    "                        \"restaurant_id\": restaurant_id,\n",
    "                        \"name\": name,\n",
    "                        \"rating\": rating,\n",
    "                        \"reviews\": reviews,\n",
    "                        \"price\": price,\n",
    "                        \"cuisine_location\": cuisine_location,\n",
    "                        \"timeslots\": \", \".join(slots),\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"   ! Error processing card {idx}: {e}\")\n",
    "                time.sleep(0.05)\n",
    "\n",
    "            # ----- CLICK NEXT PAGE ONCE -----\n",
    "            if not next_clicked:\n",
    "                try:\n",
    "                    next_button = WebDriverWait(driver, 5).until(\n",
    "                        EC.presence_of_element_located(\n",
    "                            (By.CSS_SELECTOR, 'a[aria-label=\"Go to the next page\"]')\n",
    "                        )\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "                    time.sleep(1)\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    next_clicked = True\n",
    "                    page_number += 1\n",
    "                    time.sleep(3)\n",
    "                except TimeoutException:\n",
    "                    print(\"No next page button found, finished scraping.\")\n",
    "                    break\n",
    "            else:\n",
    "                break  # already clicked once, stop here\n",
    "\n",
    "        # ----- SAVE CSV -----\n",
    "        print(\"\\n[5/6] Saving results to 'birmingham_west_midlands.csv'...\")\n",
    "        with open(\"birmingham_west_midlands.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=[\n",
    "                \"restaurant_id\", \"name\", \"rating\", \"reviews\",\n",
    "                \"price\", \"cuisine_location\", \"timeslots\"\n",
    "            ])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(all_results)\n",
    "\n",
    "        print(f\"[6/6] Scraping complete! Total restaurants: {len(all_results)}\\n\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_opentable_birmingham_one_click(URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d497092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/6] Creating fresh Chrome options...\n",
      "[2/6] Launching undetected Chrome...\n",
      "[3/6] Loading OpenTable page...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "[5/6] Extracting restaurant data...\n",
      "Found 50 restaurant cards.\n",
      "\n",
      " → Processing restaurant 1/50\n",
      " → Processing restaurant 2/50\n",
      " → Processing restaurant 3/50\n",
      " → Processing restaurant 4/50\n",
      " → Processing restaurant 5/50\n",
      " → Processing restaurant 6/50\n",
      " → Processing restaurant 7/50\n",
      " → Processing restaurant 8/50\n",
      " → Processing restaurant 9/50\n",
      " → Processing restaurant 10/50\n",
      " → Processing restaurant 11/50\n",
      " → Processing restaurant 12/50\n",
      " → Processing restaurant 13/50\n",
      " → Processing restaurant 14/50\n",
      " → Processing restaurant 15/50\n",
      " → Processing restaurant 16/50\n",
      " → Processing restaurant 17/50\n",
      " → Processing restaurant 18/50\n",
      " → Processing restaurant 19/50\n",
      " → Processing restaurant 20/50\n",
      " → Processing restaurant 21/50\n",
      " → Processing restaurant 22/50\n",
      " → Processing restaurant 23/50\n",
      " → Processing restaurant 24/50\n",
      " → Processing restaurant 25/50\n",
      " → Processing restaurant 26/50\n",
      " → Processing restaurant 27/50\n",
      " → Processing restaurant 28/50\n",
      " → Processing restaurant 29/50\n",
      " → Processing restaurant 30/50\n",
      " → Processing restaurant 31/50\n",
      " → Processing restaurant 32/50\n",
      " → Processing restaurant 33/50\n",
      " → Processing restaurant 34/50\n",
      " → Processing restaurant 35/50\n",
      " → Processing restaurant 36/50\n",
      " → Processing restaurant 37/50\n",
      " → Processing restaurant 38/50\n",
      " → Processing restaurant 39/50\n",
      " → Processing restaurant 40/50\n",
      " → Processing restaurant 41/50\n",
      " → Processing restaurant 42/50\n",
      " → Processing restaurant 43/50\n",
      " → Processing restaurant 44/50\n",
      " → Processing restaurant 45/50\n",
      " → Processing restaurant 46/50\n",
      " → Processing restaurant 47/50\n",
      " → Processing restaurant 48/50\n",
      " → Processing restaurant 49/50\n",
      " → Processing restaurant 50/50\n",
      "\n",
      "[6/6] Saving results to CSV...\n",
      "Scraping complete! Saved as restaurants.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# brighton\n",
    "import csv\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import undetected_chromedriver as uc\n",
    "\n",
    "URL = \"https://www.opentable.co.uk/s?dateTime=2026-01-31T23%3A30%3A00&covers=2&metroId=3089&regionIds%5B%5D=&neighborhoodIds%5B%5D=&term=&shouldUseLatLongSearch=false&originCorrelationId=550d3ccc-a24c-4a57-bd6e-05d0487accdf\"\n",
    "\n",
    "def scrape_opentable_uc_scroll(url):\n",
    "    print(\"[1/6] Creating fresh Chrome options...\")\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.headless = False  # make browser visible\n",
    "\n",
    "    print(\"[2/6] Launching undetected Chrome...\")\n",
    "    driver = uc.Chrome(options=options, version_main=142)\n",
    "\n",
    "    try:\n",
    "        print(\"[3/6] Loading OpenTable page...\")\n",
    "        driver.get(url)\n",
    "        time.sleep(3)\n",
    "\n",
    "        # ----- SCROLL SLOWLY TO LOAD ALL CARDS -----\n",
    "        print(\"[4/6] Scrolling page to load all restaurants...\")\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        while True:\n",
    "            driver.execute_script(\"window.scrollBy(0, 500);\")  # scroll down 500px\n",
    "            time.sleep(1)  # wait for lazy-loaded content\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break  # reached bottom\n",
    "            last_height = new_height\n",
    "\n",
    "        print(\"[5/6] Extracting restaurant data...\")\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        cards = soup.find_all(\"div\", attrs={\"data-test\": \"restaurant-card\"})\n",
    "        print(f\"Found {len(cards)} restaurant cards.\\n\")\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for idx, card in enumerate(cards, start=1):\n",
    "            print(f\" → Processing restaurant {idx}/{len(cards)}\")\n",
    "            try:\n",
    "                restaurant_id = card.get(\"data-rid\")\n",
    "\n",
    "                name_tag = card.find(\"a\", attrs={\"data-test\": \"res-card-name\"})\n",
    "                name = name_tag.get_text(strip=True) if name_tag else None\n",
    "\n",
    "                rating_tag = card.select_one(\".tSiVMQB9es0-\")\n",
    "                rating = rating_tag.get_text(strip=True) if rating_tag else None\n",
    "\n",
    "                review_tag = card.find(\"a\", attrs={\"href\": lambda x: x and \"#reviews\" in x})\n",
    "                reviews = review_tag.get_text(strip=True) if review_tag else None\n",
    "\n",
    "                price_tag = card.select_one(\".Vk-xtpOrXcE-\")\n",
    "                price = price_tag.get_text(strip=True) if price_tag else None\n",
    "\n",
    "                cuisine_tag = card.select_one('[data-test=\"cuisine-and-location\"]')\n",
    "                cuisine_location = cuisine_tag.get_text(strip=True) if cuisine_tag else None\n",
    "\n",
    "                slots = [\n",
    "                    slot.get_text(strip=True)\n",
    "                    for slot in card.select('[data-test^=\"time-slot\"] div')\n",
    "                    if slot.get_text(strip=True)\n",
    "                ]\n",
    "\n",
    "                results.append({\n",
    "                    \"restaurant_id\": restaurant_id,\n",
    "                    \"name\": name,\n",
    "                    \"rating\": rating,\n",
    "                    \"reviews\": reviews,\n",
    "                    \"price\": price,\n",
    "                    \"cuisine_location\": cuisine_location,\n",
    "                    \"timeslots\": \", \".join(slots),\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   ! Error processing card {idx}: {e}\")\n",
    "\n",
    "            time.sleep(0.05)\n",
    "\n",
    "        print(\"\\n[6/6] Saving results to CSV...\")\n",
    "        with open(\"brighton.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=[\n",
    "                \"restaurant_id\", \"name\", \"rating\", \"reviews\",\n",
    "                \"price\", \"cuisine_location\", \"timeslots\"\n",
    "            ])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(results)\n",
    "\n",
    "        print(\"Scraping complete! Saved as restaurants.csv\\n\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_opentable_uc_scroll(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2978d894-806e-4c3e-a6e7-d81da5d4f843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/6] Creating fresh Chrome options...\n",
      "[2/6] Launching undetected Chrome...\n",
      "\n",
      "[3/6] Processing page 1...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 50 restaurant cards on page 1.\n",
      " → Processing restaurant 1/50\n",
      " → Processing restaurant 2/50\n",
      " → Processing restaurant 3/50\n",
      " → Processing restaurant 4/50\n",
      " → Processing restaurant 5/50\n",
      " → Processing restaurant 6/50\n",
      " → Processing restaurant 7/50\n",
      " → Processing restaurant 8/50\n",
      " → Processing restaurant 9/50\n",
      " → Processing restaurant 10/50\n",
      " → Processing restaurant 11/50\n",
      " → Processing restaurant 12/50\n",
      " → Processing restaurant 13/50\n",
      " → Processing restaurant 14/50\n",
      " → Processing restaurant 15/50\n",
      " → Processing restaurant 16/50\n",
      " → Processing restaurant 17/50\n",
      " → Processing restaurant 18/50\n",
      " → Processing restaurant 19/50\n",
      " → Processing restaurant 20/50\n",
      " → Processing restaurant 21/50\n",
      " → Processing restaurant 22/50\n",
      " → Processing restaurant 23/50\n",
      " → Processing restaurant 24/50\n",
      " → Processing restaurant 25/50\n",
      " → Processing restaurant 26/50\n",
      " → Processing restaurant 27/50\n",
      " → Processing restaurant 28/50\n",
      " → Processing restaurant 29/50\n",
      " → Processing restaurant 30/50\n",
      " → Processing restaurant 31/50\n",
      " → Processing restaurant 32/50\n",
      " → Processing restaurant 33/50\n",
      " → Processing restaurant 34/50\n",
      " → Processing restaurant 35/50\n",
      " → Processing restaurant 36/50\n",
      " → Processing restaurant 37/50\n",
      " → Processing restaurant 38/50\n",
      " → Processing restaurant 39/50\n",
      " → Processing restaurant 40/50\n",
      " → Processing restaurant 41/50\n",
      " → Processing restaurant 42/50\n",
      " → Processing restaurant 43/50\n",
      " → Processing restaurant 44/50\n",
      " → Processing restaurant 45/50\n",
      " → Processing restaurant 46/50\n",
      " → Processing restaurant 47/50\n",
      " → Processing restaurant 48/50\n",
      " → Processing restaurant 49/50\n",
      " → Processing restaurant 50/50\n",
      "\n",
      "[3/6] Processing page 2...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 50 restaurant cards on page 2.\n",
      " → Processing restaurant 1/50\n",
      " → Processing restaurant 2/50\n",
      " → Processing restaurant 3/50\n",
      " → Processing restaurant 4/50\n",
      " → Processing restaurant 5/50\n",
      " → Processing restaurant 6/50\n",
      " → Processing restaurant 7/50\n",
      " → Processing restaurant 8/50\n",
      " → Processing restaurant 9/50\n",
      " → Processing restaurant 10/50\n",
      " → Processing restaurant 11/50\n",
      " → Processing restaurant 12/50\n",
      " → Processing restaurant 13/50\n",
      " → Processing restaurant 14/50\n",
      " → Processing restaurant 15/50\n",
      " → Processing restaurant 16/50\n",
      " → Processing restaurant 17/50\n",
      " → Processing restaurant 18/50\n",
      " → Processing restaurant 19/50\n",
      " → Processing restaurant 20/50\n",
      " → Processing restaurant 21/50\n",
      " → Processing restaurant 22/50\n",
      " → Processing restaurant 23/50\n",
      " → Processing restaurant 24/50\n",
      " → Processing restaurant 25/50\n",
      " → Processing restaurant 26/50\n",
      " → Processing restaurant 27/50\n",
      " → Processing restaurant 28/50\n",
      " → Processing restaurant 29/50\n",
      " → Processing restaurant 30/50\n",
      " → Processing restaurant 31/50\n",
      " → Processing restaurant 32/50\n",
      " → Processing restaurant 33/50\n",
      " → Processing restaurant 34/50\n",
      " → Processing restaurant 35/50\n",
      " → Processing restaurant 36/50\n",
      " → Processing restaurant 37/50\n",
      " → Processing restaurant 38/50\n",
      " → Processing restaurant 39/50\n",
      " → Processing restaurant 40/50\n",
      " → Processing restaurant 41/50\n",
      " → Processing restaurant 42/50\n",
      " → Processing restaurant 43/50\n",
      " → Processing restaurant 44/50\n",
      " → Processing restaurant 45/50\n",
      " → Processing restaurant 46/50\n",
      " → Processing restaurant 47/50\n",
      " → Processing restaurant 48/50\n",
      " → Processing restaurant 49/50\n",
      " → Processing restaurant 50/50\n",
      "\n",
      "[3/6] Processing page 3...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 50 restaurant cards on page 3.\n",
      " → Processing restaurant 1/50\n",
      " → Processing restaurant 2/50\n",
      " → Processing restaurant 3/50\n",
      " → Processing restaurant 4/50\n",
      " → Processing restaurant 5/50\n",
      " → Processing restaurant 6/50\n",
      " → Processing restaurant 7/50\n",
      " → Processing restaurant 8/50\n",
      " → Processing restaurant 9/50\n",
      " → Processing restaurant 10/50\n",
      " → Processing restaurant 11/50\n",
      " → Processing restaurant 12/50\n",
      " → Processing restaurant 13/50\n",
      " → Processing restaurant 14/50\n",
      " → Processing restaurant 15/50\n",
      " → Processing restaurant 16/50\n",
      " → Processing restaurant 17/50\n",
      " → Processing restaurant 18/50\n",
      " → Processing restaurant 19/50\n",
      " → Processing restaurant 20/50\n",
      " → Processing restaurant 21/50\n",
      " → Processing restaurant 22/50\n",
      " → Processing restaurant 23/50\n",
      " → Processing restaurant 24/50\n",
      " → Processing restaurant 25/50\n",
      " → Processing restaurant 26/50\n",
      " → Processing restaurant 27/50\n",
      " → Processing restaurant 28/50\n",
      " → Processing restaurant 29/50\n",
      " → Processing restaurant 30/50\n",
      " → Processing restaurant 31/50\n",
      " → Processing restaurant 32/50\n",
      " → Processing restaurant 33/50\n",
      " → Processing restaurant 34/50\n",
      " → Processing restaurant 35/50\n",
      " → Processing restaurant 36/50\n",
      " → Processing restaurant 37/50\n",
      " → Processing restaurant 38/50\n",
      " → Processing restaurant 39/50\n",
      " → Processing restaurant 40/50\n",
      " → Processing restaurant 41/50\n",
      " → Processing restaurant 42/50\n",
      " → Processing restaurant 43/50\n",
      " → Processing restaurant 44/50\n",
      " → Processing restaurant 45/50\n",
      " → Processing restaurant 46/50\n",
      " → Processing restaurant 47/50\n",
      " → Processing restaurant 48/50\n",
      " → Processing restaurant 49/50\n",
      " → Processing restaurant 50/50\n",
      "\n",
      "[3/6] Processing page 4...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 5 restaurant cards on page 4.\n",
      " → Processing restaurant 1/5\n",
      " → Processing restaurant 2/5\n",
      " → Processing restaurant 3/5\n",
      " → Processing restaurant 4/5\n",
      " → Processing restaurant 5/5\n",
      "\n",
      "[5/6] Saving results to 'edinburgh.csv'...\n",
      "[6/6] Scraping complete! Total restaurants: 155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# edinburgh\n",
    "URL = \"https://www.opentable.co.uk/s?dateTime=2026-01-31T23%3A30%3A00&covers=2&metroId=3191&shouldUseLatLongSearch=false&originCorrelationId=f1b4cbb5-e6d8-4c0b-902b-3bce62b50602&corrid=0f2529b5-29dd-4066-9077-6f2333afc0aa&queryUnderstandingType=none&showMap=true&sortBy=web_conversion\"\n",
    "\n",
    "def scrape_opentable_edinburgh(url):\n",
    "    print(\"[1/6] Creating fresh Chrome options...\")\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.headless = False  # make browser visible\n",
    "\n",
    "    print(\"[2/6] Launching undetected Chrome...\")\n",
    "    driver = uc.Chrome(options=options, version_main=142)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        page_number = 1\n",
    "        next_clicks_remaining = 3  # click next page 3 times for 4 pages total\n",
    "\n",
    "        while True:\n",
    "            print(f\"\\n[3/6] Processing page {page_number}...\")\n",
    "            time.sleep(3)\n",
    "\n",
    "            # ----- SCROLL SLOWLY TO LOAD ALL CARDS -----\n",
    "            print(\"[4/6] Scrolling page to load all restaurants...\")\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            while True:\n",
    "                driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "                time.sleep(1)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "\n",
    "            # Parse page\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            cards = soup.find_all(\"div\", attrs={\"data-test\": \"restaurant-card\"})\n",
    "            print(f\"Found {len(cards)} restaurant cards on page {page_number}.\")\n",
    "\n",
    "            # Extract info\n",
    "            for idx, card in enumerate(cards, start=1):\n",
    "                print(f\" → Processing restaurant {idx}/{len(cards)}\")\n",
    "                try:\n",
    "                    restaurant_id = card.get(\"data-rid\")\n",
    "\n",
    "                    name_tag = card.find(\"a\", attrs={\"data-test\": \"res-card-name\"})\n",
    "                    name = name_tag.get_text(strip=True) if name_tag else None\n",
    "\n",
    "                    rating_tag = card.select_one(\".tSiVMQB9es0-\")\n",
    "                    rating = rating_tag.get_text(strip=True) if rating_tag else None\n",
    "\n",
    "                    review_tag = card.find(\"a\", attrs={\"href\": lambda x: x and \"#reviews\" in x})\n",
    "                    reviews = review_tag.get_text(strip=True) if review_tag else None\n",
    "\n",
    "                    price_tag = card.select_one(\".Vk-xtpOrXcE-\")\n",
    "                    price = price_tag.get_text(strip=True) if price_tag else None\n",
    "\n",
    "                    cuisine_tag = card.select_one('[data-test=\"cuisine-and-location\"]')\n",
    "                    cuisine_location = cuisine_tag.get_text(strip=True) if cuisine_tag else None\n",
    "\n",
    "                    slots = [\n",
    "                        slot.get_text(strip=True)\n",
    "                        for slot in card.select('[data-test^=\"time-slot\"] div')\n",
    "                        if slot.get_text(strip=True)\n",
    "                    ]\n",
    "\n",
    "                    all_results.append({\n",
    "                        \"restaurant_id\": restaurant_id,\n",
    "                        \"name\": name,\n",
    "                        \"rating\": rating,\n",
    "                        \"reviews\": reviews,\n",
    "                        \"price\": price,\n",
    "                        \"cuisine_location\": cuisine_location,\n",
    "                        \"timeslots\": \", \".join(slots),\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"   ! Error processing card {idx}: {e}\")\n",
    "                time.sleep(0.05)\n",
    "\n",
    "            # ----- CLICK NEXT PAGE UP TO 3 TIMES -----\n",
    "            if next_clicks_remaining > 0:\n",
    "                try:\n",
    "                    next_button = WebDriverWait(driver, 5).until(\n",
    "                        EC.presence_of_element_located(\n",
    "                            (By.CSS_SELECTOR, 'a[aria-label=\"Go to the next page\"]')\n",
    "                        )\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "                    time.sleep(1)\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    next_clicks_remaining -= 1\n",
    "                    page_number += 1\n",
    "                    time.sleep(3)\n",
    "                except TimeoutException:\n",
    "                    print(\"No next page button found, finished scraping.\")\n",
    "                    break\n",
    "            else:\n",
    "                break  # clicked 3 times, stop here\n",
    "\n",
    "        # ----- SAVE CSV -----\n",
    "        print(\"\\n[5/6] Saving results to 'edinburgh.csv'...\")\n",
    "        with open(\"edinburgh.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=[\n",
    "                \"restaurant_id\", \"name\", \"rating\", \"reviews\",\n",
    "                \"price\", \"cuisine_location\", \"timeslots\"\n",
    "            ])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(all_results)\n",
    "\n",
    "        print(f\"[6/6] Scraping complete! Total restaurants: {len(all_results)}\\n\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_opentable_edinburgh(URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f335a636-7263-495f-b4f0-f063ce19bdd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/6] Creating fresh Chrome options...\n",
      "[2/6] Launching undetected Chrome...\n",
      "\n",
      "[3/6] Processing page 1...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 50 restaurant cards on page 1.\n",
      " → Processing restaurant 1/50\n",
      " → Processing restaurant 2/50\n",
      " → Processing restaurant 3/50\n",
      " → Processing restaurant 4/50\n",
      " → Processing restaurant 5/50\n",
      " → Processing restaurant 6/50\n",
      " → Processing restaurant 7/50\n",
      " → Processing restaurant 8/50\n",
      " → Processing restaurant 9/50\n",
      " → Processing restaurant 10/50\n",
      " → Processing restaurant 11/50\n",
      " → Processing restaurant 12/50\n",
      " → Processing restaurant 13/50\n",
      " → Processing restaurant 14/50\n",
      " → Processing restaurant 15/50\n",
      " → Processing restaurant 16/50\n",
      " → Processing restaurant 17/50\n",
      " → Processing restaurant 18/50\n",
      " → Processing restaurant 19/50\n",
      " → Processing restaurant 20/50\n",
      " → Processing restaurant 21/50\n",
      " → Processing restaurant 22/50\n",
      " → Processing restaurant 23/50\n",
      " → Processing restaurant 24/50\n",
      " → Processing restaurant 25/50\n",
      " → Processing restaurant 26/50\n",
      " → Processing restaurant 27/50\n",
      " → Processing restaurant 28/50\n",
      " → Processing restaurant 29/50\n",
      " → Processing restaurant 30/50\n",
      " → Processing restaurant 31/50\n",
      " → Processing restaurant 32/50\n",
      " → Processing restaurant 33/50\n",
      " → Processing restaurant 34/50\n",
      " → Processing restaurant 35/50\n",
      " → Processing restaurant 36/50\n",
      " → Processing restaurant 37/50\n",
      " → Processing restaurant 38/50\n",
      " → Processing restaurant 39/50\n",
      " → Processing restaurant 40/50\n",
      " → Processing restaurant 41/50\n",
      " → Processing restaurant 42/50\n",
      " → Processing restaurant 43/50\n",
      " → Processing restaurant 44/50\n",
      " → Processing restaurant 45/50\n",
      " → Processing restaurant 46/50\n",
      " → Processing restaurant 47/50\n",
      " → Processing restaurant 48/50\n",
      " → Processing restaurant 49/50\n",
      " → Processing restaurant 50/50\n",
      "\n",
      "[3/6] Processing page 2...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 28 restaurant cards on page 2.\n",
      " → Processing restaurant 1/28\n",
      " → Processing restaurant 2/28\n",
      " → Processing restaurant 3/28\n",
      " → Processing restaurant 4/28\n",
      " → Processing restaurant 5/28\n",
      " → Processing restaurant 6/28\n",
      " → Processing restaurant 7/28\n",
      " → Processing restaurant 8/28\n",
      " → Processing restaurant 9/28\n",
      " → Processing restaurant 10/28\n",
      " → Processing restaurant 11/28\n",
      " → Processing restaurant 12/28\n",
      " → Processing restaurant 13/28\n",
      " → Processing restaurant 14/28\n",
      " → Processing restaurant 15/28\n",
      " → Processing restaurant 16/28\n",
      " → Processing restaurant 17/28\n",
      " → Processing restaurant 18/28\n",
      " → Processing restaurant 19/28\n",
      " → Processing restaurant 20/28\n",
      " → Processing restaurant 21/28\n",
      " → Processing restaurant 22/28\n",
      " → Processing restaurant 23/28\n",
      " → Processing restaurant 24/28\n",
      " → Processing restaurant 25/28\n",
      " → Processing restaurant 26/28\n",
      " → Processing restaurant 27/28\n",
      " → Processing restaurant 28/28\n",
      "\n",
      "[5/6] Saving results to 'essex.csv'...\n",
      "[6/6] Scraping complete! Total restaurants: 78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# essex\n",
    "URL = \"https://www.opentable.co.uk/s?dateTime=2026-01-31T23%3A30%3A00&covers=2&metroId=3125&regionIds%5B%5D=&neighborhoodIds%5B%5D=&term=&shouldUseLatLongSearch=false&originCorrelationId=2f122bc1-0b38-45c8-9a50-126f2d596f96\"\n",
    "\n",
    "def scrape_opentable_essex(url):\n",
    "    print(\"[1/6] Creating fresh Chrome options...\")\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.headless = False  # make browser visible\n",
    "\n",
    "    print(\"[2/6] Launching undetected Chrome...\")\n",
    "    driver = uc.Chrome(options=options, version_main=142)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        page_number = 1\n",
    "        next_clicks_remaining = 1  # only click once\n",
    "\n",
    "        while True:\n",
    "            print(f\"\\n[3/6] Processing page {page_number}...\")\n",
    "            time.sleep(3)\n",
    "\n",
    "            # ----- SCROLL SLOWLY TO LOAD ALL CARDS -----\n",
    "            print(\"[4/6] Scrolling page to load all restaurants...\")\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            while True:\n",
    "                driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "                time.sleep(1)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "\n",
    "            # Parse page\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            cards = soup.find_all(\"div\", attrs={\"data-test\": \"restaurant-card\"})\n",
    "            print(f\"Found {len(cards)} restaurant cards on page {page_number}.\")\n",
    "\n",
    "            # Extract info\n",
    "            for idx, card in enumerate(cards, start=1):\n",
    "                print(f\" → Processing restaurant {idx}/{len(cards)}\")\n",
    "                try:\n",
    "                    restaurant_id = card.get(\"data-rid\")\n",
    "\n",
    "                    name_tag = card.find(\"a\", attrs={\"data-test\": \"res-card-name\"})\n",
    "                    name = name_tag.get_text(strip=True) if name_tag else None\n",
    "\n",
    "                    rating_tag = card.select_one(\".tSiVMQB9es0-\")\n",
    "                    rating = rating_tag.get_text(strip=True) if rating_tag else None\n",
    "\n",
    "                    review_tag = card.find(\"a\", attrs={\"href\": lambda x: x and \"#reviews\" in x})\n",
    "                    reviews = review_tag.get_text(strip=True) if review_tag else None\n",
    "\n",
    "                    price_tag = card.select_one(\".Vk-xtpOrXcE-\")\n",
    "                    price = price_tag.get_text(strip=True) if price_tag else None\n",
    "\n",
    "                    cuisine_tag = card.select_one('[data-test=\"cuisine-and-location\"]')\n",
    "                    cuisine_location = cuisine_tag.get_text(strip=True) if cuisine_tag else None\n",
    "\n",
    "                    slots = [\n",
    "                        slot.get_text(strip=True)\n",
    "                        for slot in card.select('[data-test^=\"time-slot\"] div')\n",
    "                        if slot.get_text(strip=True)\n",
    "                    ]\n",
    "\n",
    "                    all_results.append({\n",
    "                        \"restaurant_id\": restaurant_id,\n",
    "                        \"name\": name,\n",
    "                        \"rating\": rating,\n",
    "                        \"reviews\": reviews,\n",
    "                        \"price\": price,\n",
    "                        \"cuisine_location\": cuisine_location,\n",
    "                        \"timeslots\": \", \".join(slots),\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"   ! Error processing card {idx}: {e}\")\n",
    "                time.sleep(0.05)\n",
    "\n",
    "            # ----- CLICK NEXT PAGE ONCE -----\n",
    "            if next_clicks_remaining > 0:\n",
    "                try:\n",
    "                    next_button = WebDriverWait(driver, 5).until(\n",
    "                        EC.presence_of_element_located(\n",
    "                            (By.CSS_SELECTOR, 'a[aria-label=\"Go to the next page\"]')\n",
    "                        )\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "                    time.sleep(1)\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    next_clicks_remaining -= 1\n",
    "                    page_number += 1\n",
    "                    time.sleep(3)\n",
    "                except TimeoutException:\n",
    "                    print(\"No next page button found, finished scraping.\")\n",
    "                    break\n",
    "            else:\n",
    "                break  # clicked once, stop here\n",
    "\n",
    "        # ----- SAVE CSV -----\n",
    "        print(\"\\n[5/6] Saving results to 'essex.csv'...\")\n",
    "        with open(\"essex.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=[\n",
    "                \"restaurant_id\", \"name\", \"rating\", \"reviews\",\n",
    "                \"price\", \"cuisine_location\", \"timeslots\"\n",
    "            ])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(all_results)\n",
    "\n",
    "        print(f\"[6/6] Scraping complete! Total restaurants: {len(all_results)}\\n\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_opentable_essex(URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2d8030d-f6ec-4cf3-b709-ae188b70639d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/6] Creating fresh Chrome options...\n",
      "[2/6] Launching undetected Chrome...\n",
      "\n",
      "[3/6] Processing page 1...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 50 restaurant cards on page 1.\n",
      " → Processing restaurant 1/50\n",
      " → Processing restaurant 2/50\n",
      " → Processing restaurant 3/50\n",
      " → Processing restaurant 4/50\n",
      " → Processing restaurant 5/50\n",
      " → Processing restaurant 6/50\n",
      " → Processing restaurant 7/50\n",
      " → Processing restaurant 8/50\n",
      " → Processing restaurant 9/50\n",
      " → Processing restaurant 10/50\n",
      " → Processing restaurant 11/50\n",
      " → Processing restaurant 12/50\n",
      " → Processing restaurant 13/50\n",
      " → Processing restaurant 14/50\n",
      " → Processing restaurant 15/50\n",
      " → Processing restaurant 16/50\n",
      " → Processing restaurant 17/50\n",
      " → Processing restaurant 18/50\n",
      " → Processing restaurant 19/50\n",
      " → Processing restaurant 20/50\n",
      " → Processing restaurant 21/50\n",
      " → Processing restaurant 22/50\n",
      " → Processing restaurant 23/50\n",
      " → Processing restaurant 24/50\n",
      " → Processing restaurant 25/50\n",
      " → Processing restaurant 26/50\n",
      " → Processing restaurant 27/50\n",
      " → Processing restaurant 28/50\n",
      " → Processing restaurant 29/50\n",
      " → Processing restaurant 30/50\n",
      " → Processing restaurant 31/50\n",
      " → Processing restaurant 32/50\n",
      " → Processing restaurant 33/50\n",
      " → Processing restaurant 34/50\n",
      " → Processing restaurant 35/50\n",
      " → Processing restaurant 36/50\n",
      " → Processing restaurant 37/50\n",
      " → Processing restaurant 38/50\n",
      " → Processing restaurant 39/50\n",
      " → Processing restaurant 40/50\n",
      " → Processing restaurant 41/50\n",
      " → Processing restaurant 42/50\n",
      " → Processing restaurant 43/50\n",
      " → Processing restaurant 44/50\n",
      " → Processing restaurant 45/50\n",
      " → Processing restaurant 46/50\n",
      " → Processing restaurant 47/50\n",
      " → Processing restaurant 48/50\n",
      " → Processing restaurant 49/50\n",
      " → Processing restaurant 50/50\n",
      "\n",
      "[3/6] Processing page 2...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 29 restaurant cards on page 2.\n",
      " → Processing restaurant 1/29\n",
      " → Processing restaurant 2/29\n",
      " → Processing restaurant 3/29\n",
      " → Processing restaurant 4/29\n",
      " → Processing restaurant 5/29\n",
      " → Processing restaurant 6/29\n",
      " → Processing restaurant 7/29\n",
      " → Processing restaurant 8/29\n",
      " → Processing restaurant 9/29\n",
      " → Processing restaurant 10/29\n",
      " → Processing restaurant 11/29\n",
      " → Processing restaurant 12/29\n",
      " → Processing restaurant 13/29\n",
      " → Processing restaurant 14/29\n",
      " → Processing restaurant 15/29\n",
      " → Processing restaurant 16/29\n",
      " → Processing restaurant 17/29\n",
      " → Processing restaurant 18/29\n",
      " → Processing restaurant 19/29\n",
      " → Processing restaurant 20/29\n",
      " → Processing restaurant 21/29\n",
      " → Processing restaurant 22/29\n",
      " → Processing restaurant 23/29\n",
      " → Processing restaurant 24/29\n",
      " → Processing restaurant 25/29\n",
      " → Processing restaurant 26/29\n",
      " → Processing restaurant 27/29\n",
      " → Processing restaurant 28/29\n",
      " → Processing restaurant 29/29\n",
      "\n",
      "[5/6] Saving results to 'glasgow.csv'...\n",
      "[6/6] Scraping complete! Total restaurants: 79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# glasgow\n",
    "URL = \"https://www.opentable.co.uk/s?dateTime=2026-01-31T23%3A30%3A00&covers=2&metroId=3188&regionIds%5B%5D=&neighborhoodIds%5B%5D=&term=&shouldUseLatLongSearch=false&originCorrelationId=5c236a4f-f291-4199-8d33-6945dbf4ce9e\"\n",
    "\n",
    "def scrape_opentable_glasgow(url):\n",
    "    print(\"[1/6] Creating fresh Chrome options...\")\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.headless = False  # make browser visible\n",
    "\n",
    "    print(\"[2/6] Launching undetected Chrome...\")\n",
    "    driver = uc.Chrome(options=options, version_main=142)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        page_number = 1\n",
    "        next_clicks_remaining = 1  # only click once\n",
    "\n",
    "        while True:\n",
    "            print(f\"\\n[3/6] Processing page {page_number}...\")\n",
    "            time.sleep(3)\n",
    "\n",
    "            # ----- SCROLL SLOWLY TO LOAD ALL CARDS -----\n",
    "            print(\"[4/6] Scrolling page to load all restaurants...\")\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            while True:\n",
    "                driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "                time.sleep(1)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "\n",
    "            # Parse page\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            cards = soup.find_all(\"div\", attrs={\"data-test\": \"restaurant-card\"})\n",
    "            print(f\"Found {len(cards)} restaurant cards on page {page_number}.\")\n",
    "\n",
    "            # Extract info\n",
    "            for idx, card in enumerate(cards, start=1):\n",
    "                print(f\" → Processing restaurant {idx}/{len(cards)}\")\n",
    "                try:\n",
    "                    restaurant_id = card.get(\"data-rid\")\n",
    "\n",
    "                    name_tag = card.find(\"a\", attrs={\"data-test\": \"res-card-name\"})\n",
    "                    name = name_tag.get_text(strip=True) if name_tag else None\n",
    "\n",
    "                    rating_tag = card.select_one(\".tSiVMQB9es0-\")\n",
    "                    rating = rating_tag.get_text(strip=True) if rating_tag else None\n",
    "\n",
    "                    review_tag = card.find(\"a\", attrs={\"href\": lambda x: x and \"#reviews\" in x})\n",
    "                    reviews = review_tag.get_text(strip=True) if review_tag else None\n",
    "\n",
    "                    price_tag = card.select_one(\".Vk-xtpOrXcE-\")\n",
    "                    price = price_tag.get_text(strip=True) if price_tag else None\n",
    "\n",
    "                    cuisine_tag = card.select_one('[data-test=\"cuisine-and-location\"]')\n",
    "                    cuisine_location = cuisine_tag.get_text(strip=True) if cuisine_tag else None\n",
    "\n",
    "                    slots = [\n",
    "                        slot.get_text(strip=True)\n",
    "                        for slot in card.select('[data-test^=\"time-slot\"] div')\n",
    "                        if slot.get_text(strip=True)\n",
    "                    ]\n",
    "\n",
    "                    all_results.append({\n",
    "                        \"restaurant_id\": restaurant_id,\n",
    "                        \"name\": name,\n",
    "                        \"rating\": rating,\n",
    "                        \"reviews\": reviews,\n",
    "                        \"price\": price,\n",
    "                        \"cuisine_location\": cuisine_location,\n",
    "                        \"timeslots\": \", \".join(slots),\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"   ! Error processing card {idx}: {e}\")\n",
    "                time.sleep(0.05)\n",
    "\n",
    "            # ----- CLICK NEXT PAGE ONCE -----\n",
    "            if next_clicks_remaining > 0:\n",
    "                try:\n",
    "                    next_button = WebDriverWait(driver, 5).until(\n",
    "                        EC.presence_of_element_located(\n",
    "                            (By.CSS_SELECTOR, 'a[aria-label=\"Go to the next page\"]')\n",
    "                        )\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "                    time.sleep(1)\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    next_clicks_remaining -= 1\n",
    "                    page_number += 1\n",
    "                    time.sleep(3)\n",
    "                except TimeoutException:\n",
    "                    print(\"No next page button found, finished scraping.\")\n",
    "                    break\n",
    "            else:\n",
    "                break  # clicked once, stop here\n",
    "\n",
    "        # ----- SAVE CSV -----\n",
    "        print(\"\\n[5/6] Saving results to 'glasgow.csv'...\")\n",
    "        with open(\"glasgow.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=[\n",
    "                \"restaurant_id\", \"name\", \"rating\", \"reviews\",\n",
    "                \"price\", \"cuisine_location\", \"timeslots\"\n",
    "            ])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(all_results)\n",
    "\n",
    "        print(f\"[6/6] Scraping complete! Total restaurants: {len(all_results)}\\n\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_opentable_glasgow(URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "032f7a12-0f34-4c8f-9b7d-bd8821f9d205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/6] Creating fresh Chrome options...\n",
      "[2/6] Launching undetected Chrome...\n",
      "\n",
      "[3/6] Processing page 1...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 50 restaurant cards on page 1.\n",
      " → Processing restaurant 1/50\n",
      " → Processing restaurant 2/50\n",
      " → Processing restaurant 3/50\n",
      " → Processing restaurant 4/50\n",
      " → Processing restaurant 5/50\n",
      " → Processing restaurant 6/50\n",
      " → Processing restaurant 7/50\n",
      " → Processing restaurant 8/50\n",
      " → Processing restaurant 9/50\n",
      " → Processing restaurant 10/50\n",
      " → Processing restaurant 11/50\n",
      " → Processing restaurant 12/50\n",
      " → Processing restaurant 13/50\n",
      " → Processing restaurant 14/50\n",
      " → Processing restaurant 15/50\n",
      " → Processing restaurant 16/50\n",
      " → Processing restaurant 17/50\n",
      " → Processing restaurant 18/50\n",
      " → Processing restaurant 19/50\n",
      " → Processing restaurant 20/50\n",
      " → Processing restaurant 21/50\n",
      " → Processing restaurant 22/50\n",
      " → Processing restaurant 23/50\n",
      " → Processing restaurant 24/50\n",
      " → Processing restaurant 25/50\n",
      " → Processing restaurant 26/50\n",
      " → Processing restaurant 27/50\n",
      " → Processing restaurant 28/50\n",
      " → Processing restaurant 29/50\n",
      " → Processing restaurant 30/50\n",
      " → Processing restaurant 31/50\n",
      " → Processing restaurant 32/50\n",
      " → Processing restaurant 33/50\n",
      " → Processing restaurant 34/50\n",
      " → Processing restaurant 35/50\n",
      " → Processing restaurant 36/50\n",
      " → Processing restaurant 37/50\n",
      " → Processing restaurant 38/50\n",
      " → Processing restaurant 39/50\n",
      " → Processing restaurant 40/50\n",
      " → Processing restaurant 41/50\n",
      " → Processing restaurant 42/50\n",
      " → Processing restaurant 43/50\n",
      " → Processing restaurant 44/50\n",
      " → Processing restaurant 45/50\n",
      " → Processing restaurant 46/50\n",
      " → Processing restaurant 47/50\n",
      " → Processing restaurant 48/50\n",
      " → Processing restaurant 49/50\n",
      " → Processing restaurant 50/50\n",
      "\n",
      "[3/6] Processing page 2...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 20 restaurant cards on page 2.\n",
      " → Processing restaurant 1/20\n",
      " → Processing restaurant 2/20\n",
      " → Processing restaurant 3/20\n",
      " → Processing restaurant 4/20\n",
      " → Processing restaurant 5/20\n",
      " → Processing restaurant 6/20\n",
      " → Processing restaurant 7/20\n",
      " → Processing restaurant 8/20\n",
      " → Processing restaurant 9/20\n",
      " → Processing restaurant 10/20\n",
      " → Processing restaurant 11/20\n",
      " → Processing restaurant 12/20\n",
      " → Processing restaurant 13/20\n",
      " → Processing restaurant 14/20\n",
      " → Processing restaurant 15/20\n",
      " → Processing restaurant 16/20\n",
      " → Processing restaurant 17/20\n",
      " → Processing restaurant 18/20\n",
      " → Processing restaurant 19/20\n",
      " → Processing restaurant 20/20\n",
      "\n",
      "[5/6] Saving results to 'gloucestershire.csv'...\n",
      "[6/6] Scraping complete! Total restaurants: 70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gloucestershire\n",
    "URL = \"https://www.opentable.co.uk/s?dateTime=2026-01-31T23%3A30%3A00&covers=2&metroId=3185&regionIds%5B%5D=&neighborhoodIds%5B%5D=&term=&shouldUseLatLongSearch=false&originCorrelationId=0c1698da-32be-4844-82f5-3d9dc818ba40\"\n",
    "\n",
    "def scrape_opentable_gloucestershire(url):\n",
    "    print(\"[1/6] Creating fresh Chrome options...\")\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.headless = False  # make browser visible\n",
    "\n",
    "    print(\"[2/6] Launching undetected Chrome...\")\n",
    "    driver = uc.Chrome(options=options, version_main=142)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        page_number = 1\n",
    "        next_clicks_remaining = 1  # only click once\n",
    "\n",
    "        while True:\n",
    "            print(f\"\\n[3/6] Processing page {page_number}...\")\n",
    "            time.sleep(3)\n",
    "\n",
    "            # ----- SCROLL SLOWLY TO LOAD ALL CARDS -----\n",
    "            print(\"[4/6] Scrolling page to load all restaurants...\")\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            while True:\n",
    "                driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "                time.sleep(1)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "\n",
    "            # Parse page\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            cards = soup.find_all(\"div\", attrs={\"data-test\": \"restaurant-card\"})\n",
    "            print(f\"Found {len(cards)} restaurant cards on page {page_number}.\")\n",
    "\n",
    "            # Extract info\n",
    "            for idx, card in enumerate(cards, start=1):\n",
    "                print(f\" → Processing restaurant {idx}/{len(cards)}\")\n",
    "                try:\n",
    "                    restaurant_id = card.get(\"data-rid\")\n",
    "\n",
    "                    name_tag = card.find(\"a\", attrs={\"data-test\": \"res-card-name\"})\n",
    "                    name = name_tag.get_text(strip=True) if name_tag else None\n",
    "\n",
    "                    rating_tag = card.select_one(\".tSiVMQB9es0-\")\n",
    "                    rating = rating_tag.get_text(strip=True) if rating_tag else None\n",
    "\n",
    "                    review_tag = card.find(\"a\", attrs={\"href\": lambda x: x and \"#reviews\" in x})\n",
    "                    reviews = review_tag.get_text(strip=True) if review_tag else None\n",
    "\n",
    "                    price_tag = card.select_one(\".Vk-xtpOrXcE-\")\n",
    "                    price = price_tag.get_text(strip=True) if price_tag else None\n",
    "\n",
    "                    cuisine_tag = card.select_one('[data-test=\"cuisine-and-location\"]')\n",
    "                    cuisine_location = cuisine_tag.get_text(strip=True) if cuisine_tag else None\n",
    "\n",
    "                    slots = [\n",
    "                        slot.get_text(strip=True)\n",
    "                        for slot in card.select('[data-test^=\"time-slot\"] div')\n",
    "                        if slot.get_text(strip=True)\n",
    "                    ]\n",
    "\n",
    "                    all_results.append({\n",
    "                        \"restaurant_id\": restaurant_id,\n",
    "                        \"name\": name,\n",
    "                        \"rating\": rating,\n",
    "                        \"reviews\": reviews,\n",
    "                        \"price\": price,\n",
    "                        \"cuisine_location\": cuisine_location,\n",
    "                        \"timeslots\": \", \".join(slots),\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"   ! Error processing card {idx}: {e}\")\n",
    "                time.sleep(0.05)\n",
    "\n",
    "            # ----- CLICK NEXT PAGE ONCE -----\n",
    "            if next_clicks_remaining > 0:\n",
    "                try:\n",
    "                    next_button = WebDriverWait(driver, 5).until(\n",
    "                        EC.presence_of_element_located(\n",
    "                            (By.CSS_SELECTOR, 'a[aria-label=\"Go to the next page\"]')\n",
    "                        )\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "                    time.sleep(1)\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    next_clicks_remaining -= 1\n",
    "                    page_number += 1\n",
    "                    time.sleep(3)\n",
    "                except TimeoutException:\n",
    "                    print(\"No next page button found, finished scraping.\")\n",
    "                    break\n",
    "            else:\n",
    "                break  # clicked once, stop here\n",
    "\n",
    "        # ----- SAVE CSV -----\n",
    "        print(\"\\n[5/6] Saving results to 'gloucestershire.csv'...\")\n",
    "        with open(\"gloucestershire.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=[\n",
    "                \"restaurant_id\", \"name\", \"rating\", \"reviews\",\n",
    "                \"price\", \"cuisine_location\", \"timeslots\"\n",
    "            ])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(all_results)\n",
    "\n",
    "        print(f\"[6/6] Scraping complete! Total restaurants: {len(all_results)}\\n\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_opentable_gloucestershire(URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58e897f6-5c19-4867-b58f-937f0bf9d743",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/6] Creating fresh Chrome options...\n",
      "[2/6] Launching undetected Chrome...\n",
      "\n",
      "[3/6] Processing page 1...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 50 restaurant cards on page 1.\n",
      " → Processing restaurant 1/50\n",
      " → Processing restaurant 2/50\n",
      " → Processing restaurant 3/50\n",
      " → Processing restaurant 4/50\n",
      " → Processing restaurant 5/50\n",
      " → Processing restaurant 6/50\n",
      " → Processing restaurant 7/50\n",
      " → Processing restaurant 8/50\n",
      " → Processing restaurant 9/50\n",
      " → Processing restaurant 10/50\n",
      " → Processing restaurant 11/50\n",
      " → Processing restaurant 12/50\n",
      " → Processing restaurant 13/50\n",
      " → Processing restaurant 14/50\n",
      " → Processing restaurant 15/50\n",
      " → Processing restaurant 16/50\n",
      " → Processing restaurant 17/50\n",
      " → Processing restaurant 18/50\n",
      " → Processing restaurant 19/50\n",
      " → Processing restaurant 20/50\n",
      " → Processing restaurant 21/50\n",
      " → Processing restaurant 22/50\n",
      " → Processing restaurant 23/50\n",
      " → Processing restaurant 24/50\n",
      " → Processing restaurant 25/50\n",
      " → Processing restaurant 26/50\n",
      " → Processing restaurant 27/50\n",
      " → Processing restaurant 28/50\n",
      " → Processing restaurant 29/50\n",
      " → Processing restaurant 30/50\n",
      " → Processing restaurant 31/50\n",
      " → Processing restaurant 32/50\n",
      " → Processing restaurant 33/50\n",
      " → Processing restaurant 34/50\n",
      " → Processing restaurant 35/50\n",
      " → Processing restaurant 36/50\n",
      " → Processing restaurant 37/50\n",
      " → Processing restaurant 38/50\n",
      " → Processing restaurant 39/50\n",
      " → Processing restaurant 40/50\n",
      " → Processing restaurant 41/50\n",
      " → Processing restaurant 42/50\n",
      " → Processing restaurant 43/50\n",
      " → Processing restaurant 44/50\n",
      " → Processing restaurant 45/50\n",
      " → Processing restaurant 46/50\n",
      " → Processing restaurant 47/50\n",
      " → Processing restaurant 48/50\n",
      " → Processing restaurant 49/50\n",
      " → Processing restaurant 50/50\n",
      "\n",
      "[3/6] Processing page 2...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 17 restaurant cards on page 2.\n",
      " → Processing restaurant 1/17\n",
      " → Processing restaurant 2/17\n",
      " → Processing restaurant 3/17\n",
      " → Processing restaurant 4/17\n",
      " → Processing restaurant 5/17\n",
      " → Processing restaurant 6/17\n",
      " → Processing restaurant 7/17\n",
      " → Processing restaurant 8/17\n",
      " → Processing restaurant 9/17\n",
      " → Processing restaurant 10/17\n",
      " → Processing restaurant 11/17\n",
      " → Processing restaurant 12/17\n",
      " → Processing restaurant 13/17\n",
      " → Processing restaurant 14/17\n",
      " → Processing restaurant 15/17\n",
      " → Processing restaurant 16/17\n",
      " → Processing restaurant 17/17\n",
      "\n",
      "[5/6] Saving results to 'hampshire.csv'...\n",
      "[6/6] Scraping complete! Total restaurants: 67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hampshire\n",
    "URL = \"https://www.opentable.co.uk/s?dateTime=2026-01-31T23%3A30%3A00&covers=2&metroId=3092&regionIds%5B%5D=&neighborhoodIds%5B%5D=&term=&shouldUseLatLongSearch=false&originCorrelationId=937a2167-7929-4f1f-9031-8c4da62da22a\"\n",
    "\n",
    "def scrape_opentable_hampshire(url):\n",
    "    print(\"[1/6] Creating fresh Chrome options...\")\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.headless = False  # make browser visible\n",
    "\n",
    "    print(\"[2/6] Launching undetected Chrome...\")\n",
    "    driver = uc.Chrome(options=options, version_main=142)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        page_number = 1\n",
    "        next_clicks_remaining = 1  # only click once\n",
    "\n",
    "        while True:\n",
    "            print(f\"\\n[3/6] Processing page {page_number}...\")\n",
    "            time.sleep(3)\n",
    "\n",
    "            # ----- SCROLL SLOWLY TO LOAD ALL CARDS -----\n",
    "            print(\"[4/6] Scrolling page to load all restaurants...\")\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            while True:\n",
    "                driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "                time.sleep(1)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "\n",
    "            # Parse page\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            cards = soup.find_all(\"div\", attrs={\"data-test\": \"restaurant-card\"})\n",
    "            print(f\"Found {len(cards)} restaurant cards on page {page_number}.\")\n",
    "\n",
    "            # Extract info\n",
    "            for idx, card in enumerate(cards, start=1):\n",
    "                print(f\" → Processing restaurant {idx}/{len(cards)}\")\n",
    "                try:\n",
    "                    restaurant_id = card.get(\"data-rid\")\n",
    "\n",
    "                    name_tag = card.find(\"a\", attrs={\"data-test\": \"res-card-name\"})\n",
    "                    name = name_tag.get_text(strip=True) if name_tag else None\n",
    "\n",
    "                    rating_tag = card.select_one(\".tSiVMQB9es0-\")\n",
    "                    rating = rating_tag.get_text(strip=True) if rating_tag else None\n",
    "\n",
    "                    review_tag = card.find(\"a\", attrs={\"href\": lambda x: x and \"#reviews\" in x})\n",
    "                    reviews = review_tag.get_text(strip=True) if review_tag else None\n",
    "\n",
    "                    price_tag = card.select_one(\".Vk-xtpOrXcE-\")\n",
    "                    price = price_tag.get_text(strip=True) if price_tag else None\n",
    "\n",
    "                    cuisine_tag = card.select_one('[data-test=\"cuisine-and-location\"]')\n",
    "                    cuisine_location = cuisine_tag.get_text(strip=True) if cuisine_tag else None\n",
    "\n",
    "                    slots = [\n",
    "                        slot.get_text(strip=True)\n",
    "                        for slot in card.select('[data-test^=\"time-slot\"] div')\n",
    "                        if slot.get_text(strip=True)\n",
    "                    ]\n",
    "\n",
    "                    all_results.append({\n",
    "                        \"restaurant_id\": restaurant_id,\n",
    "                        \"name\": name,\n",
    "                        \"rating\": rating,\n",
    "                        \"reviews\": reviews,\n",
    "                        \"price\": price,\n",
    "                        \"cuisine_location\": cuisine_location,\n",
    "                        \"timeslots\": \", \".join(slots),\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"   ! Error processing card {idx}: {e}\")\n",
    "                time.sleep(0.05)\n",
    "\n",
    "            # ----- CLICK NEXT PAGE ONCE -----\n",
    "            if next_clicks_remaining > 0:\n",
    "                try:\n",
    "                    next_button = WebDriverWait(driver, 5).until(\n",
    "                        EC.presence_of_element_located(\n",
    "                            (By.CSS_SELECTOR, 'a[aria-label=\"Go to the next page\"]')\n",
    "                        )\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "                    time.sleep(1)\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    next_clicks_remaining -= 1\n",
    "                    page_number += 1\n",
    "                    time.sleep(3)\n",
    "                except TimeoutException:\n",
    "                    print(\"No next page button found, finished scraping.\")\n",
    "                    break\n",
    "            else:\n",
    "                break  # clicked once, stop here\n",
    "\n",
    "        # ----- SAVE CSV -----\n",
    "        print(\"\\n[5/6] Saving results to 'hampshire.csv'...\")\n",
    "        with open(\"hampshire.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=[\n",
    "                \"restaurant_id\", \"name\", \"rating\", \"reviews\",\n",
    "                \"price\", \"cuisine_location\", \"timeslots\"\n",
    "            ])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(all_results)\n",
    "\n",
    "        print(f\"[6/6] Scraping complete! Total restaurants: {len(all_results)}\\n\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_opentable_hampshire(URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b87c7353-7fce-491b-a5b5-d208d1afde1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/6] Creating fresh Chrome options...\n",
      "[2/6] Launching undetected Chrome...\n",
      "\n",
      "[3/6] Processing page 1...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 50 restaurant cards on page 1.\n",
      " → Processing restaurant 1/50\n",
      " → Processing restaurant 2/50\n",
      " → Processing restaurant 3/50\n",
      " → Processing restaurant 4/50\n",
      " → Processing restaurant 5/50\n",
      " → Processing restaurant 6/50\n",
      " → Processing restaurant 7/50\n",
      " → Processing restaurant 8/50\n",
      " → Processing restaurant 9/50\n",
      " → Processing restaurant 10/50\n",
      " → Processing restaurant 11/50\n",
      " → Processing restaurant 12/50\n",
      " → Processing restaurant 13/50\n",
      " → Processing restaurant 14/50\n",
      " → Processing restaurant 15/50\n",
      " → Processing restaurant 16/50\n",
      " → Processing restaurant 17/50\n",
      " → Processing restaurant 18/50\n",
      " → Processing restaurant 19/50\n",
      " → Processing restaurant 20/50\n",
      " → Processing restaurant 21/50\n",
      " → Processing restaurant 22/50\n",
      " → Processing restaurant 23/50\n",
      " → Processing restaurant 24/50\n",
      " → Processing restaurant 25/50\n",
      " → Processing restaurant 26/50\n",
      " → Processing restaurant 27/50\n",
      " → Processing restaurant 28/50\n",
      " → Processing restaurant 29/50\n",
      " → Processing restaurant 30/50\n",
      " → Processing restaurant 31/50\n",
      " → Processing restaurant 32/50\n",
      " → Processing restaurant 33/50\n",
      " → Processing restaurant 34/50\n",
      " → Processing restaurant 35/50\n",
      " → Processing restaurant 36/50\n",
      " → Processing restaurant 37/50\n",
      " → Processing restaurant 38/50\n",
      " → Processing restaurant 39/50\n",
      " → Processing restaurant 40/50\n",
      " → Processing restaurant 41/50\n",
      " → Processing restaurant 42/50\n",
      " → Processing restaurant 43/50\n",
      " → Processing restaurant 44/50\n",
      " → Processing restaurant 45/50\n",
      " → Processing restaurant 46/50\n",
      " → Processing restaurant 47/50\n",
      " → Processing restaurant 48/50\n",
      " → Processing restaurant 49/50\n",
      " → Processing restaurant 50/50\n",
      "\n",
      "[3/6] Processing page 2...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 36 restaurant cards on page 2.\n",
      " → Processing restaurant 1/36\n",
      " → Processing restaurant 2/36\n",
      " → Processing restaurant 3/36\n",
      " → Processing restaurant 4/36\n",
      " → Processing restaurant 5/36\n",
      " → Processing restaurant 6/36\n",
      " → Processing restaurant 7/36\n",
      " → Processing restaurant 8/36\n",
      " → Processing restaurant 9/36\n",
      " → Processing restaurant 10/36\n",
      " → Processing restaurant 11/36\n",
      " → Processing restaurant 12/36\n",
      " → Processing restaurant 13/36\n",
      " → Processing restaurant 14/36\n",
      " → Processing restaurant 15/36\n",
      " → Processing restaurant 16/36\n",
      " → Processing restaurant 17/36\n",
      " → Processing restaurant 18/36\n",
      " → Processing restaurant 19/36\n",
      " → Processing restaurant 20/36\n",
      " → Processing restaurant 21/36\n",
      " → Processing restaurant 22/36\n",
      " → Processing restaurant 23/36\n",
      " → Processing restaurant 24/36\n",
      " → Processing restaurant 25/36\n",
      " → Processing restaurant 26/36\n",
      " → Processing restaurant 27/36\n",
      " → Processing restaurant 28/36\n",
      " → Processing restaurant 29/36\n",
      " → Processing restaurant 30/36\n",
      " → Processing restaurant 31/36\n",
      " → Processing restaurant 32/36\n",
      " → Processing restaurant 33/36\n",
      " → Processing restaurant 34/36\n",
      " → Processing restaurant 35/36\n",
      " → Processing restaurant 36/36\n",
      "\n",
      "[5/6] Saving results to 'hertfordshire.csv'...\n",
      "[6/6] Scraping complete! Total restaurants: 86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hertfordshire\n",
    "URL = \"https://www.opentable.co.uk/s?dateTime=2026-01-31T23%3A30%3A00&covers=2&metroId=3128&regionIds%5B%5D=&neighborhoodIds%5B%5D=&term=&shouldUseLatLongSearch=false&originCorrelationId=5576cd00-921e-4e3f-84e7-3976d5efe639\"\n",
    "\n",
    "def scrape_opentable_hertfordshire(url):\n",
    "    print(\"[1/6] Creating fresh Chrome options...\")\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.headless = False  # make browser visible\n",
    "\n",
    "    print(\"[2/6] Launching undetected Chrome...\")\n",
    "    driver = uc.Chrome(options=options, version_main=142)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        page_number = 1\n",
    "        next_clicks_remaining = 1  # only click once\n",
    "\n",
    "        while True:\n",
    "            print(f\"\\n[3/6] Processing page {page_number}...\")\n",
    "            time.sleep(3)\n",
    "\n",
    "            # ----- SCROLL SLOWLY TO LOAD ALL CARDS -----\n",
    "            print(\"[4/6] Scrolling page to load all restaurants...\")\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            while True:\n",
    "                driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "                time.sleep(1)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "\n",
    "            # Parse page\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            cards = soup.find_all(\"div\", attrs={\"data-test\": \"restaurant-card\"})\n",
    "            print(f\"Found {len(cards)} restaurant cards on page {page_number}.\")\n",
    "\n",
    "            # Extract info\n",
    "            for idx, card in enumerate(cards, start=1):\n",
    "                print(f\" → Processing restaurant {idx}/{len(cards)}\")\n",
    "                try:\n",
    "                    restaurant_id = card.get(\"data-rid\")\n",
    "\n",
    "                    name_tag = card.find(\"a\", attrs={\"data-test\": \"res-card-name\"})\n",
    "                    name = name_tag.get_text(strip=True) if name_tag else None\n",
    "\n",
    "                    rating_tag = card.select_one(\".tSiVMQB9es0-\")\n",
    "                    rating = rating_tag.get_text(strip=True) if rating_tag else None\n",
    "\n",
    "                    review_tag = card.find(\"a\", attrs={\"href\": lambda x: x and \"#reviews\" in x})\n",
    "                    reviews = review_tag.get_text(strip=True) if review_tag else None\n",
    "\n",
    "                    price_tag = card.select_one(\".Vk-xtpOrXcE-\")\n",
    "                    price = price_tag.get_text(strip=True) if price_tag else None\n",
    "\n",
    "                    cuisine_tag = card.select_one('[data-test=\"cuisine-and-location\"]')\n",
    "                    cuisine_location = cuisine_tag.get_text(strip=True) if cuisine_tag else None\n",
    "\n",
    "                    slots = [\n",
    "                        slot.get_text(strip=True)\n",
    "                        for slot in card.select('[data-test^=\"time-slot\"] div')\n",
    "                        if slot.get_text(strip=True)\n",
    "                    ]\n",
    "\n",
    "                    all_results.append({\n",
    "                        \"restaurant_id\": restaurant_id,\n",
    "                        \"name\": name,\n",
    "                        \"rating\": rating,\n",
    "                        \"reviews\": reviews,\n",
    "                        \"price\": price,\n",
    "                        \"cuisine_location\": cuisine_location,\n",
    "                        \"timeslots\": \", \".join(slots),\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"   ! Error processing card {idx}: {e}\")\n",
    "                time.sleep(0.05)\n",
    "\n",
    "            # ----- CLICK NEXT PAGE ONCE -----\n",
    "            if next_clicks_remaining > 0:\n",
    "                try:\n",
    "                    next_button = WebDriverWait(driver, 5).until(\n",
    "                        EC.presence_of_element_located(\n",
    "                            (By.CSS_SELECTOR, 'a[aria-label=\"Go to the next page\"]')\n",
    "                        )\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "                    time.sleep(1)\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    next_clicks_remaining -= 1\n",
    "                    page_number += 1\n",
    "                    time.sleep(3)\n",
    "                except TimeoutException:\n",
    "                    print(\"No next page button found, finished scraping.\")\n",
    "                    break\n",
    "            else:\n",
    "                break  # clicked once, stop here\n",
    "\n",
    "        # ----- SAVE CSV -----\n",
    "        print(\"\\n[5/6] Saving results to 'hertfordshire.csv'...\")\n",
    "        with open(\"hertfordshire.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=[\n",
    "                \"restaurant_id\", \"name\", \"rating\", \"reviews\",\n",
    "                \"price\", \"cuisine_location\", \"timeslots\"\n",
    "            ])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(all_results)\n",
    "\n",
    "        print(f\"[6/6] Scraping complete! Total restaurants: {len(all_results)}\\n\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_opentable_hertfordshire(URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d44f58b-30b5-4dd9-961a-355443892ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/6] Creating fresh Chrome options...\n",
      "[2/6] Launching undetected Chrome...\n",
      "\n",
      "[3/6] Processing page 1...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 50 restaurant cards on page 1.\n",
      " → Processing restaurant 1/50\n",
      " → Processing restaurant 2/50\n",
      " → Processing restaurant 3/50\n",
      " → Processing restaurant 4/50\n",
      " → Processing restaurant 5/50\n",
      " → Processing restaurant 6/50\n",
      " → Processing restaurant 7/50\n",
      " → Processing restaurant 8/50\n",
      " → Processing restaurant 9/50\n",
      " → Processing restaurant 10/50\n",
      " → Processing restaurant 11/50\n",
      " → Processing restaurant 12/50\n",
      " → Processing restaurant 13/50\n",
      " → Processing restaurant 14/50\n",
      " → Processing restaurant 15/50\n",
      " → Processing restaurant 16/50\n",
      " → Processing restaurant 17/50\n",
      " → Processing restaurant 18/50\n",
      " → Processing restaurant 19/50\n",
      " → Processing restaurant 20/50\n",
      " → Processing restaurant 21/50\n",
      " → Processing restaurant 22/50\n",
      " → Processing restaurant 23/50\n",
      " → Processing restaurant 24/50\n",
      " → Processing restaurant 25/50\n",
      " → Processing restaurant 26/50\n",
      " → Processing restaurant 27/50\n",
      " → Processing restaurant 28/50\n",
      " → Processing restaurant 29/50\n",
      " → Processing restaurant 30/50\n",
      " → Processing restaurant 31/50\n",
      " → Processing restaurant 32/50\n",
      " → Processing restaurant 33/50\n",
      " → Processing restaurant 34/50\n",
      " → Processing restaurant 35/50\n",
      " → Processing restaurant 36/50\n",
      " → Processing restaurant 37/50\n",
      " → Processing restaurant 38/50\n",
      " → Processing restaurant 39/50\n",
      " → Processing restaurant 40/50\n",
      " → Processing restaurant 41/50\n",
      " → Processing restaurant 42/50\n",
      " → Processing restaurant 43/50\n",
      " → Processing restaurant 44/50\n",
      " → Processing restaurant 45/50\n",
      " → Processing restaurant 46/50\n",
      " → Processing restaurant 47/50\n",
      " → Processing restaurant 48/50\n",
      " → Processing restaurant 49/50\n",
      " → Processing restaurant 50/50\n",
      "\n",
      "[3/6] Processing page 2...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 50 restaurant cards on page 2.\n",
      " → Processing restaurant 1/50\n",
      " → Processing restaurant 2/50\n",
      " → Processing restaurant 3/50\n",
      " → Processing restaurant 4/50\n",
      " → Processing restaurant 5/50\n",
      " → Processing restaurant 6/50\n",
      " → Processing restaurant 7/50\n",
      " → Processing restaurant 8/50\n",
      " → Processing restaurant 9/50\n",
      " → Processing restaurant 10/50\n",
      " → Processing restaurant 11/50\n",
      " → Processing restaurant 12/50\n",
      " → Processing restaurant 13/50\n",
      " → Processing restaurant 14/50\n",
      " → Processing restaurant 15/50\n",
      " → Processing restaurant 16/50\n",
      " → Processing restaurant 17/50\n",
      " → Processing restaurant 18/50\n",
      " → Processing restaurant 19/50\n",
      " → Processing restaurant 20/50\n",
      " → Processing restaurant 21/50\n",
      " → Processing restaurant 22/50\n",
      " → Processing restaurant 23/50\n",
      " → Processing restaurant 24/50\n",
      " → Processing restaurant 25/50\n",
      " → Processing restaurant 26/50\n",
      " → Processing restaurant 27/50\n",
      " → Processing restaurant 28/50\n",
      " → Processing restaurant 29/50\n",
      " → Processing restaurant 30/50\n",
      " → Processing restaurant 31/50\n",
      " → Processing restaurant 32/50\n",
      " → Processing restaurant 33/50\n",
      " → Processing restaurant 34/50\n",
      " → Processing restaurant 35/50\n",
      " → Processing restaurant 36/50\n",
      " → Processing restaurant 37/50\n",
      " → Processing restaurant 38/50\n",
      " → Processing restaurant 39/50\n",
      " → Processing restaurant 40/50\n",
      " → Processing restaurant 41/50\n",
      " → Processing restaurant 42/50\n",
      " → Processing restaurant 43/50\n",
      " → Processing restaurant 44/50\n",
      " → Processing restaurant 45/50\n",
      " → Processing restaurant 46/50\n",
      " → Processing restaurant 47/50\n",
      " → Processing restaurant 48/50\n",
      " → Processing restaurant 49/50\n",
      " → Processing restaurant 50/50\n",
      "\n",
      "[3/6] Processing page 3...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 50 restaurant cards on page 3.\n",
      " → Processing restaurant 1/50\n",
      " → Processing restaurant 2/50\n",
      " → Processing restaurant 3/50\n",
      " → Processing restaurant 4/50\n",
      " → Processing restaurant 5/50\n",
      " → Processing restaurant 6/50\n",
      " → Processing restaurant 7/50\n",
      " → Processing restaurant 8/50\n",
      " → Processing restaurant 9/50\n",
      " → Processing restaurant 10/50\n",
      " → Processing restaurant 11/50\n",
      " → Processing restaurant 12/50\n",
      " → Processing restaurant 13/50\n",
      " → Processing restaurant 14/50\n",
      " → Processing restaurant 15/50\n",
      " → Processing restaurant 16/50\n",
      " → Processing restaurant 17/50\n",
      " → Processing restaurant 18/50\n",
      " → Processing restaurant 19/50\n",
      " → Processing restaurant 20/50\n",
      " → Processing restaurant 21/50\n",
      " → Processing restaurant 22/50\n",
      " → Processing restaurant 23/50\n",
      " → Processing restaurant 24/50\n",
      " → Processing restaurant 25/50\n",
      " → Processing restaurant 26/50\n",
      " → Processing restaurant 27/50\n",
      " → Processing restaurant 28/50\n",
      " → Processing restaurant 29/50\n",
      " → Processing restaurant 30/50\n",
      " → Processing restaurant 31/50\n",
      " → Processing restaurant 32/50\n",
      " → Processing restaurant 33/50\n",
      " → Processing restaurant 34/50\n",
      " → Processing restaurant 35/50\n",
      " → Processing restaurant 36/50\n",
      " → Processing restaurant 37/50\n",
      " → Processing restaurant 38/50\n",
      " → Processing restaurant 39/50\n",
      " → Processing restaurant 40/50\n",
      " → Processing restaurant 41/50\n",
      " → Processing restaurant 42/50\n",
      " → Processing restaurant 43/50\n",
      " → Processing restaurant 44/50\n",
      " → Processing restaurant 45/50\n",
      " → Processing restaurant 46/50\n",
      " → Processing restaurant 47/50\n",
      " → Processing restaurant 48/50\n",
      " → Processing restaurant 49/50\n",
      " → Processing restaurant 50/50\n",
      "\n",
      "[3/6] Processing page 4...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "Found 14 restaurant cards on page 4.\n",
      " → Processing restaurant 1/14\n",
      " → Processing restaurant 2/14\n",
      " → Processing restaurant 3/14\n",
      " → Processing restaurant 4/14\n",
      " → Processing restaurant 5/14\n",
      " → Processing restaurant 6/14\n",
      " → Processing restaurant 7/14\n",
      " → Processing restaurant 8/14\n",
      " → Processing restaurant 9/14\n",
      " → Processing restaurant 10/14\n",
      " → Processing restaurant 11/14\n",
      " → Processing restaurant 12/14\n",
      " → Processing restaurant 13/14\n",
      " → Processing restaurant 14/14\n",
      "\n",
      "[5/6] Saving results to 'kent.csv'...\n",
      "[6/6] Scraping complete! Total restaurants: 164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# kent\n",
    "URL = \"https://www.opentable.co.uk/s?dateTime=2026-01-31T23%3A30%3A00&covers=2&metroId=3098&regionIds%5B%5D=&neighborhoodIds%5B%5D=&term=&shouldUseLatLongSearch=false&originCorrelationId=d0d4ad73-ecca-4eb8-9098-847ad558744c\"\n",
    "\n",
    "def scrape_opentable_kent(url):\n",
    "    print(\"[1/6] Creating fresh Chrome options...\")\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.headless = False  # make browser visible\n",
    "\n",
    "    print(\"[2/6] Launching undetected Chrome...\")\n",
    "    driver = uc.Chrome(options=options, version_main=142)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        page_number = 1\n",
    "        next_clicks_remaining = 3  # click 3 times for 4 pages total\n",
    "\n",
    "        while True:\n",
    "            print(f\"\\n[3/6] Processing page {page_number}...\")\n",
    "            time.sleep(3)\n",
    "\n",
    "            # ----- SCROLL SLOWLY TO LOAD ALL CARDS -----\n",
    "            print(\"[4/6] Scrolling page to load all restaurants...\")\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            while True:\n",
    "                driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "                time.sleep(1)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "\n",
    "            # Parse page\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            cards = soup.find_all(\"div\", attrs={\"data-test\": \"restaurant-card\"})\n",
    "            print(f\"Found {len(cards)} restaurant cards on page {page_number}.\")\n",
    "\n",
    "            # Extract info\n",
    "            for idx, card in enumerate(cards, start=1):\n",
    "                print(f\" → Processing restaurant {idx}/{len(cards)}\")\n",
    "                try:\n",
    "                    restaurant_id = card.get(\"data-rid\")\n",
    "\n",
    "                    name_tag = card.find(\"a\", attrs={\"data-test\": \"res-card-name\"})\n",
    "                    name = name_tag.get_text(strip=True) if name_tag else None\n",
    "\n",
    "                    rating_tag = card.select_one(\".tSiVMQB9es0-\")\n",
    "                    rating = rating_tag.get_text(strip=True) if rating_tag else None\n",
    "\n",
    "                    review_tag = card.find(\"a\", attrs={\"href\": lambda x: x and \"#reviews\" in x})\n",
    "                    reviews = review_tag.get_text(strip=True) if review_tag else None\n",
    "\n",
    "                    price_tag = card.select_one(\".Vk-xtpOrXcE-\")\n",
    "                    price = price_tag.get_text(strip=True) if price_tag else None\n",
    "\n",
    "                    cuisine_tag = card.select_one('[data-test=\"cuisine-and-location\"]')\n",
    "                    cuisine_location = cuisine_tag.get_text(strip=True) if cuisine_tag else None\n",
    "\n",
    "                    slots = [\n",
    "                        slot.get_text(strip=True)\n",
    "                        for slot in card.select('[data-test^=\"time-slot\"] div')\n",
    "                        if slot.get_text(strip=True)\n",
    "                    ]\n",
    "\n",
    "                    all_results.append({\n",
    "                        \"restaurant_id\": restaurant_id,\n",
    "                        \"name\": name,\n",
    "                        \"rating\": rating,\n",
    "                        \"reviews\": reviews,\n",
    "                        \"price\": price,\n",
    "                        \"cuisine_location\": cuisine_location,\n",
    "                        \"timeslots\": \", \".join(slots),\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"   ! Error processing card {idx}: {e}\")\n",
    "                time.sleep(0.05)\n",
    "\n",
    "            # ----- CLICK NEXT PAGE -----\n",
    "            if next_clicks_remaining > 0:\n",
    "                try:\n",
    "                    next_button = WebDriverWait(driver, 5).until(\n",
    "                        EC.presence_of_element_located(\n",
    "                            (By.CSS_SELECTOR, 'a[aria-label=\"Go to the next page\"]')\n",
    "                        )\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "                    time.sleep(1)\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    next_clicks_remaining -= 1\n",
    "                    page_number += 1\n",
    "                    time.sleep(3)\n",
    "                except TimeoutException:\n",
    "                    print(\"No next page button found, finished scraping.\")\n",
    "                    break\n",
    "            else:\n",
    "                break  # clicked 3 times, stop here\n",
    "\n",
    "        # ----- SAVE CSV -----\n",
    "        print(\"\\n[5/6] Saving results to 'kent.csv'...\")\n",
    "        with open(\"kent.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=[\n",
    "                \"restaurant_id\", \"name\", \"rating\", \"reviews\",\n",
    "                \"price\", \"cuisine_location\", \"timeslots\"\n",
    "            ])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(all_results)\n",
    "\n",
    "        print(f\"[6/6] Scraping complete! Total restaurants: {len(all_results)}\\n\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_opentable_kent(URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e62968a8-0c78-4479-a560-a4c28752170c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/6] Creating fresh Chrome options...\n",
      "[2/6] Launching undetected Chrome...\n",
      "[3/6] Loading OpenTable page...\n",
      "[4/6] Scrolling page to load all restaurants...\n",
      "[5/6] Extracting restaurant data...\n",
      "Found 50 restaurant cards.\n",
      "\n",
      " → Processing restaurant 1/50\n",
      " → Processing restaurant 2/50\n",
      " → Processing restaurant 3/50\n",
      " → Processing restaurant 4/50\n",
      " → Processing restaurant 5/50\n",
      " → Processing restaurant 6/50\n",
      " → Processing restaurant 7/50\n",
      " → Processing restaurant 8/50\n",
      " → Processing restaurant 9/50\n",
      " → Processing restaurant 10/50\n",
      " → Processing restaurant 11/50\n",
      " → Processing restaurant 12/50\n",
      " → Processing restaurant 13/50\n",
      " → Processing restaurant 14/50\n",
      " → Processing restaurant 15/50\n",
      " → Processing restaurant 16/50\n",
      " → Processing restaurant 17/50\n",
      " → Processing restaurant 18/50\n",
      " → Processing restaurant 19/50\n",
      " → Processing restaurant 20/50\n",
      " → Processing restaurant 21/50\n",
      " → Processing restaurant 22/50\n",
      " → Processing restaurant 23/50\n",
      " → Processing restaurant 24/50\n",
      " → Processing restaurant 25/50\n",
      " → Processing restaurant 26/50\n",
      " → Processing restaurant 27/50\n",
      " → Processing restaurant 28/50\n",
      " → Processing restaurant 29/50\n",
      " → Processing restaurant 30/50\n",
      " → Processing restaurant 31/50\n",
      " → Processing restaurant 32/50\n",
      " → Processing restaurant 33/50\n",
      " → Processing restaurant 34/50\n",
      " → Processing restaurant 35/50\n",
      " → Processing restaurant 36/50\n",
      " → Processing restaurant 37/50\n",
      " → Processing restaurant 38/50\n",
      " → Processing restaurant 39/50\n",
      " → Processing restaurant 40/50\n",
      " → Processing restaurant 41/50\n",
      " → Processing restaurant 42/50\n",
      " → Processing restaurant 43/50\n",
      " → Processing restaurant 44/50\n",
      " → Processing restaurant 45/50\n",
      " → Processing restaurant 46/50\n",
      " → Processing restaurant 47/50\n",
      " → Processing restaurant 48/50\n",
      " → Processing restaurant 49/50\n",
      " → Processing restaurant 50/50\n",
      "\n",
      "[6/6] Saving results to CSV...\n",
      "Scraping complete! Saved as restaurants.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# liverpool\n",
    "URL = \"https://www.opentable.co.uk/s?dateTime=2026-01-31T23%3A30%3A00&covers=2&metroId=3176&regionIds%5B%5D=&neighborhoodIds%5B%5D=&term=&shouldUseLatLongSearch=false&originCorrelationId=004ce382-43c3-4c64-bccc-4ab5d52c374c\"\n",
    "def scrape_opentable_uc_scroll(url):\n",
    "    print(\"[1/6] Creating fresh Chrome options...\")\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.headless = False  # make browser visible\n",
    "\n",
    "    print(\"[2/6] Launching undetected Chrome...\")\n",
    "    driver = uc.Chrome(options=options, version_main=142)\n",
    "\n",
    "    try:\n",
    "        print(\"[3/6] Loading OpenTable page...\")\n",
    "        driver.get(url)\n",
    "        time.sleep(3)\n",
    "\n",
    "        # ----- SCROLL SLOWLY TO LOAD ALL CARDS -----\n",
    "        print(\"[4/6] Scrolling page to load all restaurants...\")\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        while True:\n",
    "            driver.execute_script(\"window.scrollBy(0, 500);\")  # scroll down 500px\n",
    "            time.sleep(1)  # wait for lazy-loaded content\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break  # reached bottom\n",
    "            last_height = new_height\n",
    "\n",
    "        print(\"[5/6] Extracting restaurant data...\")\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        cards = soup.find_all(\"div\", attrs={\"data-test\": \"restaurant-card\"})\n",
    "        print(f\"Found {len(cards)} restaurant cards.\\n\")\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for idx, card in enumerate(cards, start=1):\n",
    "            print(f\" → Processing restaurant {idx}/{len(cards)}\")\n",
    "            try:\n",
    "                restaurant_id = card.get(\"data-rid\")\n",
    "\n",
    "                name_tag = card.find(\"a\", attrs={\"data-test\": \"res-card-name\"})\n",
    "                name = name_tag.get_text(strip=True) if name_tag else None\n",
    "\n",
    "                rating_tag = card.select_one(\".tSiVMQB9es0-\")\n",
    "                rating = rating_tag.get_text(strip=True) if rating_tag else None\n",
    "\n",
    "                review_tag = card.find(\"a\", attrs={\"href\": lambda x: x and \"#reviews\" in x})\n",
    "                reviews = review_tag.get_text(strip=True) if review_tag else None\n",
    "\n",
    "                price_tag = card.select_one(\".Vk-xtpOrXcE-\")\n",
    "                price = price_tag.get_text(strip=True) if price_tag else None\n",
    "\n",
    "                cuisine_tag = card.select_one('[data-test=\"cuisine-and-location\"]')\n",
    "                cuisine_location = cuisine_tag.get_text(strip=True) if cuisine_tag else None\n",
    "\n",
    "                slots = [\n",
    "                    slot.get_text(strip=True)\n",
    "                    for slot in card.select('[data-test^=\"time-slot\"] div')\n",
    "                    if slot.get_text(strip=True)\n",
    "                ]\n",
    "\n",
    "                results.append({\n",
    "                    \"restaurant_id\": restaurant_id,\n",
    "                    \"name\": name,\n",
    "                    \"rating\": rating,\n",
    "                    \"reviews\": reviews,\n",
    "                    \"price\": price,\n",
    "                    \"cuisine_location\": cuisine_location,\n",
    "                    \"timeslots\": \", \".join(slots),\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   ! Error processing card {idx}: {e}\")\n",
    "\n",
    "            time.sleep(0.05)\n",
    "\n",
    "        print(\"\\n[6/6] Saving results to CSV...\")\n",
    "        with open(\"liverpool.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=[\n",
    "                \"restaurant_id\", \"name\", \"rating\", \"reviews\",\n",
    "                \"price\", \"cuisine_location\", \"timeslots\"\n",
    "            ])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(results)\n",
    "\n",
    "        print(\"Scraping complete! Saved as restaurants.csv\\n\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_opentable_uc_scroll(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e1aae4-1803-4d4c-867e-3ecbae0b850a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
